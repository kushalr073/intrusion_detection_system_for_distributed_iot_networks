{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('iot23_combined.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "del df['uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample dataframe (replace this with your actual data)\n",
    "# df = pd.read_csv('your_data.csv')  # Load your actual dataset\n",
    "\n",
    "# List of columns you want to encode (adjust as necessary)\n",
    "columns_to_encode = ['proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', \n",
    "                     'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', \n",
    "                     'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', \n",
    "                     'conn_state_S1', 'conn_state_S2', 'conn_state_S3', \n",
    "                     'conn_state_SF', 'conn_state_SH', 'conn_state_SHR', \n",
    "                     'service_-', 'service_dhcp', 'service_dns', 'service_http', \n",
    "                     'service_irc', 'service_ssh', 'service_ssl']\n",
    "\n",
    "# Loop through each column and apply label encoding for True/False\n",
    "for column in columns_to_encode:\n",
    "    df[column] = df[column].apply(lambda x: 1 if x == True else 0)\n",
    "\n",
    "# Check the first few rows of the dataframe after encoding\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'ts' and 'missed_bytes' columns\n",
    "df = df.drop(['ts', 'missed_bytes'], axis=1)\n",
    "\n",
    "# Check the first few rows of the dataframe after dropping the columns\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "df = df[~df['label'].isin(['Okiru-Attack', 'C&C-Mirai'])]\n",
    "# # Assuming `df_c` is your dataset\n",
    "# # Step 1: Identify the majority and minority classes\n",
    "# majority_class = 'PartOfAHorizontalPortScan'  # Replace with your majority class label\n",
    "# minority_classes = df['label'].unique()\n",
    "# minority_classes = [cls for cls in minority_classes if cls != majority_class]\n",
    "\n",
    "# # Step 2: Downsample the majority class\n",
    "# df_majority = df[df['label'] == majority_class]\n",
    "# df_minority = df[df['label'] != majority_class]\n",
    "\n",
    "# # Determine the target size (based on the largest minority class)\n",
    "# target_size = df_minority['label'].value_counts().max()\n",
    "\n",
    "# df_majority_downsampled = resample(df_majority,\n",
    "#                                    replace=False,    # Sample without replacement\n",
    "#                                    n_samples=target_size,  # Match minority size\n",
    "#                                    random_state=42)\n",
    "\n",
    "# # Step 3: Combine downsampled majority class with the minority classes\n",
    "# df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# # Step 4: Shuffle the dataset\n",
    "# df = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # Display the balanced and shuffled dataset\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Label encode the 'label' column\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "# Check the first few rows of the dataframe after encoding\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical_features = ['orig_bytes', 'resp_bytes', 'duration', 'orig_pkts', 'resp_pkts']\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'df' is your dataframe with 'label' column as the target variable\n",
    "X = df.drop('label', axis=1)  # Features (excluding the label column)\n",
    "y = df['label']  # Label column\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (accuracy score)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Optionally, check feature importance\n",
    "print(\"Feature importances:\", xgb_model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.concat([pd.DataFrame(X_val), pd.DataFrame(y_val, columns=['label'])], axis=1)\n",
    "\n",
    "validation_data.to_csv(\"validation_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Optionally, you can check feature importance\n",
    "print(\"Feature importances:\", rf_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'df' is your dataframe with 'label' column as the target variable\n",
    "\n",
    "\n",
    "# Initialize DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (accuracy score)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Optionally, check feature importances\n",
    "print(\"Feature importances:\", dt_model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained XGBoost model to a file\n",
    "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
    "print(\"Model saved to xgb_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved XGBoost model\n",
    "loaded_model = joblib.load(\"xgb_model.pkl\")\n",
    "\n",
    "# Use the loaded model for predictions or further evaluation\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(f'Accuracy with loaded model: {accuracy_loaded * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('validation_dataset.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
